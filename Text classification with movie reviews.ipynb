{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = keras.datasets.imdb # Importing the dataset from Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>num_words = 10000</code> variable takes the reviews only 10000 words and refuses the other that have different length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the variable train_data is located an integer number that \n",
    "# represents a word, however it needs to be represented in actual text \n",
    "(train_data, train_labels), (test_data, test_labels) = data.load_data(num_words = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the integer numbers into actual words annotations\n",
    "\n",
    "The first is to create a dictionary, fortunately it is already done by Tensorflow.\n",
    "\n",
    "<code>data.get_word_index()</code> function returns tuples of type string so that it can be put on a dictionary to eventually map them and put to each integer value ***v*** a key *(word)* ***k***  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = data.get_word_index()\n",
    "word_index = {k:(v + 3) for k, v in word_index.items()} # The reason for starting +3 values\n",
    "                                                        # after is because exist some special characters\n",
    "\n",
    "word_index[\"<PAD>\"] = 0  # Padding\n",
    "word_index[\"<START>\"] = 1 # Start\n",
    "word_index[\"<UNK>\"] = 2 # Unknown\n",
    "word_index[\"<UNUSED>\"] =  3 # Unused\n",
    "\n",
    "# Swap all the values in the keys, now the key (word) is first and then the value  \n",
    "# this is basically so the the values of the word (the integers) point to a word (key)\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data annotations\n",
    "\n",
    "Given that we don't know the size and shape of the inputs it is neccesary to know them to start modeling the NN.\n",
    "\n",
    "So that, the padding tag <code> \"PAD\" </code> is used to define a definitive length of all the data, this is, ***it is going to be a allowed a ceratain ammount of words in each review***. In this case the number will be 250 word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trimming the data\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data, value = word_index[\"<PAD>\"], padding = \"post\", maxlen = 250)\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(train_data, value = word_index[\"<PAD>\"], padding = \"post\", maxlen = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_review(text):\n",
    "    '''\n",
    "    Function that decodes the text of the movie reviews and returns a\n",
    "    readable words.\n",
    "    \n",
    "    Inputs: The integer values corresponding to a word\n",
    "    \n",
    "    Outputs: The key (word) that corresponds to the integer values    \n",
    "    '''\n",
    "    # If there is a word that is not in the dictionary then it puts\n",
    "    # a question mark (?)\n",
    "    return \" \".join([reverse_word_index.get(i, \"?\") for i in text])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture annotations\n",
    "\n",
    "The purpose of the model is to find out whether the review is ***GOOD*** or ***BAD*** \n",
    "\n",
    "There are two ways of doing the model for a NN, the first is directly as in [Crash Course TensorFlow](http://localhost:8888/notebooks/Crash%20Course%20Tensorflow%20.ipynb#reference1) and the other is by using the method <code>.add()</code> in which as parameter will get the desired configuration that we want to give to the NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential() # Creating the model \n",
    "model.add(keras.layers.Embedding(10000, 16)) # Input layer\n",
    "model.add(keras.layers.GlobalAveragePooling1D()) # Hidden layer\n",
    "model.add(keras.layers.Dense(16, activation = \"relu\")) # Hidden layer\n",
    "model.add(keras.layers.Dense(1, activation = \"sigmoid\")) # Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # Useful to visualize how the NN is composed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
